{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35088e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Laptop Solution\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input,decode_predictions\n",
    "from keras import backend as K\n",
    "from keras.layers import add, Conv2D,MaxPooling2D,UpSampling2D,Input,BatchNormalization, RepeatVector, Reshape\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203e16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath_x=\"./Train/Train/low/\"\n",
    "InputPath_y=\"./Train/Train/high/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b058dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laptop Solution\\AppData\\Local\\Temp\\ipykernel_13448\\1673296872.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img=iio.imread(InputPath_x+\"2.png\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 600, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio as iio\n",
    "img=iio.imread(InputPath_x+\"2.png\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f7bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/485 [00:00<?, ?it/s]C:\\Users\\Laptop Solution\\AppData\\Local\\Temp\\ipykernel_13448\\1981446455.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_x=iio.imread(InputPath_x+imgDir)\n",
      "C:\\Users\\Laptop Solution\\AppData\\Local\\Temp\\ipykernel_13448\\1981446455.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_y=iio.imread(InputPath_x+imgDir)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 485/485 [00:20<00:00, 24.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "X=[]\n",
    "y=[]\n",
    "for imgDir in tqdm(os.listdir(InputPath_x)[1:]):\n",
    "    \n",
    "    img_x=iio.imread(InputPath_x+imgDir)\n",
    "    img_y=iio.imread(InputPath_x+imgDir)\n",
    "    X.append(img_x)\n",
    "    y.append(img_y)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e07097",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d80945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485, 400, 600, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81856e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InstantiateModel(in_):\n",
    "#     model_1 = Conv2D(3,(3,3), activation='relu',padding='same',strides=1)(in_)\n",
    "#     model_1 = Conv2D(18,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = Conv2D(18,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = MaxPooling2D(pool_size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(54,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = MaxPooling2D(pool_size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(162,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = MaxPooling2D(pool_size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(288,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = MaxPooling2D(pool_size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(288,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(162,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(54,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(18,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "#     model_1 = Conv2D(18,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = Conv2D(3,(3,3),activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_add = add([in_,model_1])\n",
    "#     return model_add\n",
    "\n",
    "def InstantiateModel(in_):\n",
    "    # Initial convolution layers\n",
    "    model_1 = Conv2D(3, (3, 3), activation='relu', padding='same', strides=1)(in_)\n",
    "    model_1 = Conv2D(18, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    # Encoder blocks with downsampling\n",
    "    model_1 = Conv2D(18, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    model_1 = MaxPooling2D(pool_size=(2, 2), padding='same')(model_1)  # Ensure padding is 'same'\n",
    "    \n",
    "    model_1 = Conv2D(54, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    model_1 = MaxPooling2D(pool_size=(2, 2), padding='same')(model_1)  # Ensure padding is 'same'\n",
    "    \n",
    "    model_1 = Conv2D(162, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    model_1 = MaxPooling2D(pool_size=(2, 2), padding='same')(model_1)  # Ensure padding is 'same'\n",
    "    \n",
    "    model_1 = Conv2D(288, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    model_1 = MaxPooling2D(pool_size=(2, 2), padding='same')(model_1)  # Ensure padding is 'same'\n",
    "    \n",
    "    # Bottleneck\n",
    "    model_1 = Conv2D(288, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    # Decoder blocks with upsampling\n",
    "    model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "    model_1 = Conv2D(162, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "    model_1 = Conv2D(54, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "    model_1 = Conv2D(18, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    model_1 = UpSampling2D(size=(2, 2))(model_1)\n",
    "    model_1 = Conv2D(18, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    # Final convolution layer to match the input shape\n",
    "    model_1 = Conv2D(3, (3, 3), activation='relu', padding='same', strides=1)(model_1)\n",
    "    \n",
    "    # Add the input to the output\n",
    "    model_add = add([in_, model_1])\n",
    "    return model_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a79f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InstantiateModel(in_):\n",
    "    \n",
    "#     model_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(in_)\n",
    "#     model_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_1)\n",
    "#     model_1 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_1)\n",
    "    \n",
    "#     model_2 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(in_)\n",
    "#     model_2 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)\n",
    "    \n",
    "#     model_2_0 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)\n",
    "    \n",
    "#     model_add = add([model_1,model_2,model_2_0])\n",
    "    \n",
    "#     model_3 = Conv2D(64,(3,3), activation='relu',padding='same',strides=1)(model_add)\n",
    "#     model_3 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_3)\n",
    "#     model_3 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3)\n",
    "    \n",
    "#     model_3_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_add)\n",
    "#     model_3_1 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3_1)\n",
    "    \n",
    "#     model_3_2 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add)\n",
    "    \n",
    "#     model_add_2 = add([model_3_1,model_3_2,model_3])\n",
    "    \n",
    "#     model_4 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_2)\n",
    "#     model_4_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add)\n",
    "#     #Extension\n",
    "#     model_add_3 = add([model_4_1,model_add_2,model_4])\n",
    "    \n",
    "#     model_5 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_3)\n",
    "#     model_5 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add_3)\n",
    "    \n",
    "#     model_5 = Conv2D(3,(3,3), activation='relu',padding='same',strides=1)(model_5)\n",
    "    \n",
    "#     return model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd8d951",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (400, 600, 3) and (400, 608, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m Input_Sample \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m600\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m Output_ \u001b[38;5;241m=\u001b[39m InstantiateModel(Input_Sample)\n\u001b[0;32m      3\u001b[0m Model_Enhancer \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mInput_Sample, outputs\u001b[38;5;241m=\u001b[39mOutput_)\n",
      "Cell \u001b[1;32mIn[14], line 63\u001b[0m, in \u001b[0;36mInstantiateModel\u001b[1;34m(in_)\u001b[0m\n\u001b[0;32m     60\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m3\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)(model_1)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Add the input to the output\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m model_add \u001b[38;5;241m=\u001b[39m add([in_, model_1])\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_add\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\merging\\add.py:92\u001b[0m, in \u001b[0;36madd\u001b[1;34m(inputs, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.layers.add\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Functional interface to the `tf.keras.layers.Add` layer.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Add(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)(inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\merging\\base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[1;34m(self, shape1, shape2)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m---> 74\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     75\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (400, 600, 3) and (400, 608, 3)"
     ]
    }
   ],
   "source": [
    "Input_Sample = Input(shape=(400, 600,3))\n",
    "Output_ = InstantiateModel(Input_Sample)\n",
    "Model_Enhancer = Model(inputs=Input_Sample, outputs=Output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Enhancer.compile(optimizer=\"adam\", loss='mean_squared_error',metrics=['mae','psnr'])\n",
    "Model_Enhancer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b32cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "WARNING:tensorflow:From C:\\Users\\Laptop Solution\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_Enhancer.fit(X, y, epochs=55, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea573e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
