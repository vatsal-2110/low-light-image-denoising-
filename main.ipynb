{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "MAX_TRAIN_IMAGES = 300\n",
    "\n",
    "def read_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image,channels=3)\n",
    "    image.set_shape([400,600,3])\n",
    "    image = tf.cast(image,dtype=tf.float32)/255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_data(low_light_image_path,enhanced_image_path):\n",
    "    low_light_image = read_image(low_light_image_path)\n",
    "    enhanced_image = read_image(enhanced_image_path)\n",
    "    return low_light_image,enhanced_image\n",
    "\n",
    "\n",
    "def get_dataset(low_light_images, enhanced_images):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images, enhanced_images))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_low_light_images = sorted(glob(\"./Train/Train/low/*\"))[:MAX_TRAIN_IMAGES]\n",
    "train_enhanced_images = sorted(glob(\"./Train/Train/high/*\"))[:MAX_TRAIN_IMAGES]\n",
    "\n",
    "val_low_light_images = sorted(glob(\"./Train/Train/low/*\"))[MAX_TRAIN_IMAGES:]\n",
    "val_enhanced_images = sorted(glob(\"./Train/Train/low/*\"))[MAX_TRAIN_IMAGES:]\n",
    "\n",
    "train_dataset = get_dataset(train_low_light_images,train_enhanced_images)\n",
    "val_dataset = get_dataset(val_low_light_images,val_enhanced_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SKFF(multiscale_feature_1, multiscale_feature_2, multiscale_feature_3):\n",
    "    channels=list(multiscale_feature_1.shape)[-1]\n",
    "    combined_feature = layers.Add()(\n",
    "        [multiscale_feature_1, multiscale_feature_2, multiscale_feature_3]\n",
    "    )\n",
    "    gap = layers.GlobalAveragePooling2D()(combined_feature)\n",
    "    channel_wise_stat = layers.Reshape((1,1,channels))(gap)\n",
    "    compact_feature_representation = layers.Conv2D(\n",
    "        filters=channels//8,kernel_size=(1,1),activation='relu'\n",
    "    )(channel_wise_stat)\n",
    "    feature_descriptor_1 = layers.Conv2D(\n",
    "        channels,kernel_size=(1,1),activation='softmax'\n",
    "    )(compact_feature_representation)\n",
    "    feature_descriptor_2 = layers.Conv2D(\n",
    "        channels,kernel_size=(1,1),activation='softmax'\n",
    "    )(compact_feature_representation)\n",
    "    feature_descriptor_3 = layers.Conv2D(\n",
    "        channels,kernel_size=(1,1),activation='softmax'\n",
    "    )(compact_feature_representation)\n",
    "    feature_1 = multiscale_feature_1*feature_descriptor_1\n",
    "    feature_2 = multiscale_feature_2*feature_descriptor_2\n",
    "    feature_3 = multiscale_feature_3*feature_descriptor_3\n",
    "    aggregate_feature = layers.Add()([feature_1,feature_2,feature_3])\n",
    "    return aggregate_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f586dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelPooling(layers.Layer):\n",
    "    def __init__(self, axis=-1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.axis = axis\n",
    "        self.concat = layers.Concatenate(axis=self.axis)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        average_pooling = tf.expand_dims(tf.reduce_mean(inputs, axis=-1), axis=-1)\n",
    "        max_pooling = tf.expand_dims(tf.reduce_max(inputs, axis=-1), axis=-1)\n",
    "        return self.concat([average_pooling, max_pooling])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"axis\": self.axis})\n",
    "\n",
    "        \n",
    "def spatial_attention_block(input_tensor):\n",
    "    compressed_feature = ChannelPooling(axis=-1)(input_tensor)\n",
    "    feature_map = layers.Conv2D(1,kernel_size=(1,1))(compressed_feature)\n",
    "    feature_map = keras.activations.sigmoid(feature_map)\n",
    "    return input_tensor*feature_map\n",
    "\n",
    "\n",
    "def channel_attention_block(input_tensor):\n",
    "    channels = list(input_tensor.shape)[-1]\n",
    "    avg_pooling= layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    feature_descriptor = layers.Reshape((1,1,channels))(avg_pooling)\n",
    "    feature_activations = layers.Conv2D(\n",
    "        filters=channels // 8, kernel_size=(1, 1), activation=\"relu\"\n",
    "    )(feature_descriptor)\n",
    "    feature_activations = layers.Conv2D(\n",
    "        filters=channels, kernel_size=(1, 1), activation=\"sigmoid\"\n",
    "    )(feature_activations)\n",
    "    return input_tensor * feature_activations\n",
    "\n",
    "\n",
    "def dual_attention_unit_block(input_tensor):\n",
    "    channels = list(input_tensor.shape)[-1]\n",
    "    feature_map = layers.Conv2D(\n",
    "        channels, kernel_size=(3,3),padding='same',activation='relu'\n",
    "    )(input_tensor)\n",
    "    feature_map = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(\n",
    "        feature_map\n",
    "    )\n",
    "    channel_attention = channel_attention_block(feature_map)\n",
    "    spatial_attention = spatial_attention_block(feature_map)\n",
    "    concatenation = layers.Concatenate(axis=-1)([channel_attention,spatial_attention])\n",
    "    concatenation = layers.Conv2D(channels, kernel_size=(1, 1))(concatenation)\n",
    "    return layers.Add()([input_tensor,concatenation])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sampling_module(input_tensor):\n",
    "    channels = list(input_tensor.shape)[-1]\n",
    "    main_branch = layers.Conv2D(channels,kernel_size=(1,1),activation ='relu')(input_tensor)\n",
    "    main_branch = layers.Conv2D(\n",
    "        channels,kernel_size=(3,3),padding='same',activation ='relu')(main_branch)\n",
    "    main_branch = layers.MaxPooling2D()(main_branch)\n",
    "    main_branch = layers.Conv2D(channels * 2, kernel_size=(1, 1))(main_branch)\n",
    "    skip_branch = layers.MaxPooling2D()(input_tensor)\n",
    "    skip_branch = layers.Conv2D(channels * 2, kernel_size=(1, 1))(skip_branch)\n",
    "    return layers.Add()([main_branch,skip_branch])\n",
    "\n",
    "def up_sampling_module(input_tensor):\n",
    "    channels = list(input_tensor.shape)[-1]\n",
    "    main_branch = layers.Conv2D(channels,kernel_size=(1,1),activation ='relu')(input_tensor)\n",
    "    main_branch = layers.Conv2D(\n",
    "        channels,kernel_size=(3,3),padding='same',activation ='relu')(main_branch)\n",
    "    main_branch = layers.UpSampling2D()(main_branch)\n",
    "    main_branch = layers.Conv2D(channels // 2, kernel_size=(1, 1))(main_branch)\n",
    "    skip_branch = layers.UpSampling2D()(input_tensor)\n",
    "    skip_branch = layers.Conv2D(channels // 2, kernel_size=(1, 1))(skip_branch)\n",
    "    return layers.Add()([main_branch,skip_branch])\n",
    "\n",
    "\n",
    "def MRB_block(input_tensor,channels):\n",
    "    level_1 = input_tensor\n",
    "    level_2 = down_sampling_module(level_1)\n",
    "    level_3 = down_sampling_module(level_2)\n",
    "    \n",
    "    level_1_dau = dual_attention_unit_block(level_1)\n",
    "    level_2_dau = dual_attention_unit_block(level_2)\n",
    "    level_3_dau = dual_attention_unit_block(level_3)\n",
    "    \n",
    "    level_1_skff = SKFF(level_1_dau, \n",
    "                        up_sampling_module(level_2_dau),\n",
    "                        up_sampling_module(up_sampling_module(level_3_dau)),)\n",
    "    level_2_skff = SKFF(down_sampling_module(level_1_dau),\n",
    "                       level_2_dau,\n",
    "                       up_sampling_module(level_3_dau),)\n",
    "    level_3_skff = SKFF(down_sampling_module(down_sampling_module(level_1_dau)),\n",
    "                       down_sampling_module(level_2_dau),\n",
    "                       level_3_dau,)\n",
    "    \n",
    "    level_1_dau_2 = dual_attention_unit_block(level_1_skff)\n",
    "    level_2_dau_2 = up_sampling_module(dual_attention_unit_block(level_2_skff))\n",
    "    level_3_dau_2 = up_sampling_module(up_sampling_module(dual_attention_unit_block(level_3_skff)))\n",
    "    \n",
    "    skff = SKFF(level_1_dau_2,level_2_dau_2,level_3_dau_2)\n",
    "    conv = layers.Conv2D(channels, kernel_size = (3,3), padding = 'same')(skff)\n",
    "    return layers.Add()([input_tensor, conv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_residual_group(input_tensor, num_mrb, channels):\n",
    "    conv1 = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(input_tensor)\n",
    "    for _ in range(num_mrb):\n",
    "        conv1 = MRB_block(conv1, channels)\n",
    "    conv2 = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(conv1)\n",
    "    return layers.Add()([conv2, input_tensor])\n",
    "\n",
    "\n",
    "def mirnet_model(num_rrg, num_mrb, channels):\n",
    "    input_tensor = keras.Input(shape=[None, None, 3])\n",
    "    x1 = layers.Conv2D(channels, kernel_size=(3, 3), padding=\"same\")(input_tensor)\n",
    "    for _ in range(num_rrg):\n",
    "        x1 = recursive_residual_group(x1, num_mrb, channels)\n",
    "    conv = layers.Conv2D(3, kernel_size=(3, 3), padding=\"same\")(x1)\n",
    "    output_tensor = layers.Add()([input_tensor, conv])\n",
    "    return keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model = mirnet_model(num_rrg=3, num_mrb=2, channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charbonnier_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.square(y_true - y_pred) + tf.square(1e-3)))\n",
    "\n",
    "\n",
    "def peak_signal_noise_ratio(y_true, y_pred):\n",
    "    return tf.image.psnr(y_pred, y_true, max_val=255.0)\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=charbonnier_loss,\n",
    "    metrics=[peak_signal_noise_ratio],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_peak_signal_noise_ratio\",\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            min_delta=1e-7,\n",
    "            mode=\"max\",\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(value, name):\n",
    "    plt.plot(history.history[value], label=f\"train_{name.lower()}\")\n",
    "    plt.plot(history.history[f\"val_{value}\"], label=f\"val_{name.lower()}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(name)\n",
    "    plt.title(f\"Train and Validation {name} Over Epochs\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(\"loss\", \"Loss\")\n",
    "plot_history(\"peak_signal_noise_ratio\", \"PSNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def postprocess_image(image):\n",
    "    image = np.squeeze(image, axis=0)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(image)\n",
    "    return image\n",
    "\n",
    "test_dir = './test/low/'\n",
    "predicted_dir = './test/predicted/'\n",
    "os.makedirs(predicted_dir, exist_ok=True)\n",
    "for image_name in os.listdir(test_dir):\n",
    "    if image_name.endswith('.png'):\n",
    "        image_path = os.path.join(test_dir, image_name)\n",
    "        input_image = preprocess_image(image_path)\n",
    "        denoised_image = model.predict(input_image)\n",
    "        denoised_image = postprocess_image(denoised_image)\n",
    "        output_path = os.path.join(predicted_dir, 'denoised_' + image_name)\n",
    "        denoised_image.save(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
